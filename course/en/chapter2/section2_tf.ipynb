{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agniji/HuggingFace/blob/main/course/en/chapter2/section2_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EWaOSFRPZaW"
      },
      "source": [
        "# Behind the pipeline (TensorFlow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSEtrbaWPZae"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8OA52k5PZag"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wZ-UrmWPZai",
        "outputId": "9e301c66-6233-4a5c-a802-04c479a9644b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG0ZP7fNPZal"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_2jJ8aYPZam",
        "outputId": "1cf77a80-bad9-45f3-edb6-6039af41e605"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
              "        array([\n",
              "            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
              "            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
              "        ], dtype=int32)>, \n",
              "    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
              "        array([\n",
              "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "        ], dtype=int32)>\n",
              "}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ApIerpZPZan"
      },
      "outputs": [],
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = TFAutoModel.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-kAJzfAPZap",
        "outputId": "e91aa06f-ef85-4465-91ad-ec4a905d44f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 16, 768)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = model(inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNTLvA7iPZaq"
      },
      "outputs": [],
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGbd4U0OPZas",
        "outputId": "425609fe-babd-4247-b50e-34839c245d84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LUgC8gNPZat",
        "outputId": "42d6689c-e164-4f83-cb2a-4e749b79ebfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "    array([[-1.5606991,  1.6122842],\n",
              "           [ 4.169231 , -3.3464472]], dtype=float32)>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IPkxtUSPZau",
        "outputId": "2fcc7e30-088e-4a23-d0fd-ff4ff8f657f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tf.Tensor(\n",
              "[[4.01951671e-02 9.59804833e-01]\n",
              " [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSl7Ur1jPZav",
        "outputId": "b6def158-95be-47a7-b152-5613a4102589"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.id2label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Example data.\n",
        "# In reality, the strings are usually longer and there are 11 possible classes\n",
        "texts = [\n",
        "    \"This is the first sentence.\",\n",
        "    \"This is the second sentence.\",\n",
        "    \"This is another sentence.\",\n",
        "    \"Finally, the last sentence.\",\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    [0.99, 0.91, 0.11, 0.10, 0.01],\n",
        "    [0.89, 0.51, 0.01, 0.10, 0.01],\n",
        "    [0.39, 0.21, 0.11, 0.10, 0.11],\n",
        "    [0.29, 0.91, 0.51, 0.20, 0.51],\n",
        "]\n",
        "\n",
        "\n",
        "train_texts = texts[:2]\n",
        "train_labels = labels[:2]\n",
        "\n",
        "eval_texts = texts[2:]\n",
        "eval_labels = labels[2:]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "train_encodings = tokenizer(train_texts, padding=\"max_length\", truncation=True, max_length=512)\n",
        "eval_encodings = tokenizer(eval_texts, padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "\n",
        "class TextClassifierDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = TextClassifierDataset(train_encodings, train_labels)\n",
        "eval_dataset = TextClassifierDataset(eval_encodings, eval_labels)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    problem_type=\"multi_label_classification\",\n",
        "    num_labels=5\n",
        ")\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\".\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_arguments,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "6SrA9AfgUWx2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Behind the pipeline (TensorFlow)",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}